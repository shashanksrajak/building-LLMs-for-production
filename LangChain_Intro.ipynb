{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5n4/MX2ZFJyDDBUhj0kKY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashanksrajak/building-LLMs-for-production/blob/main/LangChain_Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU \"langchain[openai]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9Y3CPshRrie",
        "outputId": "0d235980-977a-4e07-a74c-bd8022d2dd6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZIRhwVOaQK3n"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import init_chat_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "refactor this code!!!"
      ],
      "metadata": {
        "id": "AZlianuMWyCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "u_MO5Sq5Sqq2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
        "\n",
        "model.invoke(\"Hello Shashank!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov7-RlNrQuBY",
        "outputId": "606f0183-ff24-46e1-a354-4c92e64f6e7a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 12, 'total_tokens': 22, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BSn5UObP5D0Ofmvk0ZzpyDAzjR6Lb', 'finish_reason': 'stop', 'logprobs': None}, id='run-9d955e47-48ce-4d1b-9ff4-ac2a39a29563-0', usage_metadata={'input_tokens': 12, 'output_tokens': 10, 'total_tokens': 22, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(\"Translate the following from English into Hindi\"),\n",
        "    HumanMessage(\"hi!\"),\n",
        "]\n",
        "\n",
        "model.invoke(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UgA7xKqRg7l",
        "outputId": "9f88b24d-12cd-47ab-aa85-1169203ca445"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='नमस्ते!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 20, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BSn5Vydcs09zep0IqEYTM90qkcwFM', 'finish_reason': 'stop', 'logprobs': None}, id='run-9b01a0de-1b43-467e-b32a-25fc0e390f2c-0', usage_metadata={'input_tokens': 20, 'output_tokens': 6, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Template\n",
        "\n",
        "Take input from user and put that input in the predefined template and then send this message to the user"
      ],
      "metadata": {
        "id": "Dt8UJtXQT5tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "system_template = \"Translate the following from English into {language}\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        ")\n",
        "\n",
        "prompt = prompt_template.invoke({\"language\": \"Hindi\", \"text\": \"Are you loving LangChain!\"})\n",
        "\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hG1Ms9ETzwf",
        "outputId": "e07afa79-a1a0-4ffc-e654-b72d6fb006bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Hindi', additional_kwargs={}, response_metadata={}), HumanMessage(content='Are you loving LangChain!', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can pass this prompt which took user input to the model and invoke the model to get back a response."
      ],
      "metadata": {
        "id": "UnSZ5aIyUvi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.invoke(prompt)\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2EIsSTWUn8d",
        "outputId": "bcb2fe28-d226-427b-b93a-f5dd3b8fbb1d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='क्या आप लैंगचेन को पसंद कर रहे हैं!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 24, 'total_tokens': 37, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BSn5WcUIohnj7gGCIw1fBL1WaEi94', 'finish_reason': 'stop', 'logprobs': None}, id='run-f9fdbb54-87b5-4c4d-aa26-f543a6575b50-0', usage_metadata={'input_tokens': 24, 'output_tokens': 13, 'total_tokens': 37, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "prompt_template = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
        "\n",
        "prompt = prompt_template.invoke({\"topic\": \"cats\"})"
      ],
      "metadata": {
        "id": "1W8rnKP3U5gF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.invoke(prompt)\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_O-3GflXVgGq",
        "outputId": "27297c83-14c1-4277-c227-345003565251"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why was the cat sitting on the computer?\\n\\nBecause it wanted to keep an eye on the mouse!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "food_idea_template = PromptTemplate.from_template(\"Suggest me a good food for {occassion}\")\n",
        "food_idea_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6o6Pof8Vsqq",
        "outputId": "b0e3e4b0-233f-4c1d-a345-3c6fdb2db3c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['occassion'], input_types={}, partial_variables={}, template='Suggest me a good food for {occassion}')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = food_idea_template.invoke({\"occassion\": \"dinner\"})\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBGt9cfxWGsE",
        "outputId": "7d103070-378b-4b63-a412-1cbbaacb32bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text='Suggest me a good food for dinner')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.invoke(prompt)\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "DdyolxJMWN0l",
        "outputId": "6bdb8402-6bea-41fa-e66c-dbedce61a631"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sure! Here are a few dinner suggestions based on different preferences:\\n\\n1. **Healthy Option**: Grilled salmon with quinoa and steamed broccoli. You can add a squeeze of lemon for extra flavor.\\n\\n2. **Comfort Food**: Creamy chicken Alfredo pasta served with garlic bread and a side Caesar salad.\\n\\n3. **Vegetarian Delight**: Stuffed bell peppers filled with a mixture of black beans, corn, quinoa, and topped with avocado slices.\\n\\n4. **Quick and Easy**: Tacos with your choice of protein (chicken, beef, or tofu), topped with fresh salsa, lettuce, and cheese.\\n\\n5. **Asian Cuisine**: Stir-fried vegetables with tofu or shrimp, served over jasmine rice and a side of spring rolls.\\n\\n6. **Mediterranean Feast**: Chicken or lamb gyros with tzatziki sauce, served with a Greek salad and pita bread.\\n\\nLet me know if you have any specific dietary requirements or cravings!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chains\n",
        "The real power of LangChain lies with Chains. Oh! This is in the name itself, why LangChain!!\n",
        "\n",
        "We can chain different tasks (runnables).\n",
        "\n",
        "Refer -> https://python.langchain.com/docs/concepts/runnables/\n",
        "\n",
        " LangChain Expression Language (LCEL):"
      ],
      "metadata": {
        "id": "TDOFt8w6WZnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "food_chain = food_idea_template | model"
      ],
      "metadata": {
        "id": "npujVnE2WUhN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food_chain.invoke({\"occassion\": \"lunch\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4Iq69YMuPUh",
        "outputId": "d4ede49b-61f5-478f-b3c1-77fc25e02941"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Here are a few delicious lunch ideas you might enjoy:\\n\\n1. **Grilled Chicken Salad**: A mix of greens, cherry tomatoes, avocado, and grilled chicken, drizzled with a light vinaigrette.\\n\\n2. **Quinoa Bowl**: Quinoa topped with roasted vegetables, chickpeas, and a tahini sauce.\\n\\n3. **Turkey and Avocado Wrap**: Sliced turkey, avocado, lettuce, and tomato wrapped in a whole wheat tortilla.\\n\\n4. **Mediterranean Pita**: Whole wheat pita stuffed with hummus, cucumbers, olives, and feta cheese.\\n\\n5. **Sushi Rolls**: A selection of vegetable or fish sushi rolls, served with soy sauce and wasabi.\\n\\n6. **Vegetable Stir-Fry**: A mix of your favorite vegetables stir-fried with tofu or chicken, served over brown rice or noodles.\\n\\n7. **Lentil Soup and Whole Grain Bread**: Hearty lentil soup served with a slice of whole-grain bread.\\n\\nChoose one that fits your mood or dietary preferences!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 217, 'prompt_tokens': 14, 'total_tokens': 231, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'id': 'chatcmpl-BSn648446539qfRTbC37MXbqNro7F', 'finish_reason': 'stop', 'logprobs': None}, id='run-9a758232-e2ad-4f3e-9a42-6541c6aaa79e-0', usage_metadata={'input_tokens': 14, 'output_tokens': 217, 'total_tokens': 231, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "food_chain = food_idea_template | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "K_kt98ONuhE5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "food_chain.invoke({\"occassion\": \"lunch\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "rbEPTRXuu0NR",
        "outputId": "8dc08286-c46b-474a-9bc9-7a4515d319e8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here are a few delicious and nutritious lunch options you might enjoy:\\n\\n1. **Grilled Chicken Salad**: Mixed greens topped with grilled chicken, cherry tomatoes, cucumbers, avocado, and a light vinaigrette.\\n\\n2. **Quinoa Bowl**: Quinoa topped with black beans, corn, diced bell peppers, avocado, and a squeeze of lime.\\n\\n3. **Vegetable Stir-Fry**: Seasonal vegetables stir-fried with tofu or chicken, served over brown rice or noodles with soy sauce.\\n\\n4. **Turkey and Avocado Wrap**: Sliced turkey, avocado, lettuce, and tomato wrapped in a whole grain tortilla, served with a side of carrot sticks.\\n\\n5. **Mediterranean Pita**: Whole wheat pita stuffed with hummus, cucumber, tomato, olives, and feta cheese.\\n\\n6. **Lentil Soup**: A hearty lentil soup paired with whole-grain bread or a side salad.\\n\\n7. **Stuffed Bell Peppers**: Bell peppers filled with a mixture of ground turkey, rice, tomatoes, and spices, baked until tender.\\n\\nChoose one that fits your mood and dietary preferences!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}